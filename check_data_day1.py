#!/usr/bin/env python3
"""
Data Recovery Check Script
Verifies what data is still available after git cleanup
"""

import os
import sqlite3
import pandas as pd
from pathlib import Path
import json
from datetime import datetime

def check_file_system():
    """Check what files still exist on disk"""
    print("üìÅ CHECKING FILE SYSTEM...")
    print("=" * 50)
    
    # Key directories to check
    directories = [
        "database",
        "data", 
        "src",
        "logs"
    ]
    
    for dir_name in directories:
        dir_path = Path(dir_name)
        if dir_path.exists():
            print(f"‚úÖ {dir_name}/ directory exists")
            
            # List contents
            files = list(dir_path.rglob("*"))
            if files:
                print(f"   Contains {len(files)} items:")
                for file in sorted(files)[:10]:  # Show first 10
                    if file.is_file():
                        size_mb = file.stat().st_size / (1024 * 1024)
                        print(f"   - {file} ({size_mb:.1f} MB)")
                if len(files) > 10:
                    print(f"   ... and {len(files) - 10} more items")
            else:
                print(f"   üìÅ Empty directory")
        else:
            print(f"‚ùå {dir_name}/ directory missing")
    
    # Check for database files specifically
    print(f"\nüóÑÔ∏è  DATABASE FILES:")
    db_files = list(Path(".").rglob("*.db")) + list(Path(".").rglob("*.sqlite*"))
    
    if db_files:
        for db_file in db_files:
            size_mb = db_file.stat().st_size / (1024 * 1024)
            print(f"   ‚úÖ {db_file} ({size_mb:.1f} MB)")
    else:
        print("   ‚ùå No database files found")
    
    return db_files

def check_database_content(db_files):
    """Check content of database files"""
    print(f"\nüíæ CHECKING DATABASE CONTENT...")
    print("=" * 50)
    
    for db_file in db_files:
        try:
            print(f"\nüìä Database: {db_file}")
            
            with sqlite3.connect(str(db_file)) as conn:
                # Get all tables
                tables_df = pd.read_sql(
                    "SELECT name FROM sqlite_master WHERE type='table'", 
                    conn
                )
                
                if len(tables_df) == 0:
                    print("   ‚ùå No tables found")
                    continue
                
                print(f"   ‚úÖ Tables found: {tables_df['name'].tolist()}")
                
                # Check each table
                for table in tables_df['name']:
                    try:
                        count_result = pd.read_sql(
                            f"SELECT COUNT(*) as count FROM {table}", 
                            conn
                        )
                        count = count_result['count'][0]
                        print(f"   - {table}: {count:,} rows")
                        
                        # Show sample data for main tables
                        if table in ['reviews', 'products', 'users'] and count > 0:
                            sample = pd.read_sql(f"SELECT * FROM {table} LIMIT 3", conn)
                            print(f"     Columns: {list(sample.columns)}")
                            
                    except Exception as e:
                        print(f"   ‚ö†Ô∏è  {table}: Error reading ({e})")
                
        except Exception as e:
            print(f"   ‚ùå Could not read database {db_file}: {e}")

def check_processed_data():
    """Check if our processed data is available"""
    print(f"\nüéØ CHECKING YOUR DAY 1 WORK...")
    print("=" * 50)
    
    # Try to connect to main database
    db_path = "database/review_intelligence.db"
    
    if not Path(db_path).exists():
        # Try alternative locations
        alt_paths = [
            "./review_intelligence.db",
            "review_intelligence.db", 
            "database/reviews.db"
        ]
        
        for alt_path in alt_paths:
            if Path(alt_path).exists():
                db_path = alt_path
                break
        else:
            print("‚ùå Main database not found!")
            return False
    
    try:
        with sqlite3.connect(db_path) as conn:
            # Check reviews table
            reviews_count = pd.read_sql(
                "SELECT COUNT(*) as count FROM reviews", 
                conn
            )['count'][0]
            
            if reviews_count > 0:
                print(f"‚úÖ REVIEWS DATA INTACT: {reviews_count:,} reviews")
                
                # Get rating distribution
                rating_dist = pd.read_sql(
                    "SELECT rating, COUNT(*) as count FROM reviews GROUP BY rating ORDER BY rating", 
                    conn
                )
                print("   Rating distribution:")
                for _, row in rating_dist.iterrows():
                    print(f"   - {row['rating']} stars: {row['count']:,} reviews")
                
                # Check data quality
                sample_reviews = pd.read_sql(
                    "SELECT review_text, rating, product_id FROM reviews LIMIT 5", 
                    conn
                )
                
                print(f"\n   Sample data preview:")
                for i, row in sample_reviews.iterrows():
                    text_preview = row['review_text'][:50] + "..." if len(row['review_text']) > 50 else row['review_text']
                    print(f"   - Rating {row['rating']}: {text_preview}")
                
                return True
            else:
                print("‚ùå Reviews table is empty")
                return False
                
    except Exception as e:
        print(f"‚ùå Could not check reviews data: {e}")
        return False

def check_etl_reports():
    """Check for ETL pipeline reports"""
    print(f"\nüìã CHECKING ETL REPORTS...")
    print("=" * 30)
    
    # Look for ETL reports
    report_files = list(Path(".").rglob("etl_report_*.json"))
    
    if report_files:
        print(f"‚úÖ Found {len(report_files)} ETL reports:")
        
        for report_file in sorted(report_files)[-3:]:  # Show last 3
            try:
                with open(report_file, 'r') as f:
                    report = json.load(f)
                
                timestamp = report.get('pipeline_execution', {}).get('timestamp', 'Unknown')
                final_records = report.get('data_summary', {}).get('final_records', 0)
                quality_score = report.get('quality_metrics', {}).get('overall_score', 0)
                
                print(f"   - {report_file.name}")
                print(f"     Time: {timestamp}")
                print(f"     Records: {final_records:,}")
                print(f"     Quality: {quality_score:.1%}")
                
            except Exception as e:
                print(f"   ‚ö†Ô∏è  Could not read {report_file}: {e}")
    else:
        print("‚ö†Ô∏è  No ETL reports found")

def recovery_recommendations():
    """Provide recovery recommendations"""
    print(f"\nüîß RECOVERY OPTIONS...")
    print("=" * 50)
    
    print("‚úÖ YOUR CODE IS SAFE:")
    print("   - All Python files (.py) are intact")
    print("   - Configuration files preserved")
    print("   - Database structure maintained")
    
    print(f"\nüìä WHAT WAS REMOVED:")
    print("   - Raw CSV files (data/Reviews.csv)")
    print("   - Large data files from git tracking")
    print("   - Git history of large files")
    
    print(f"\nüöÄ IF DATA IS MISSING:")
    print("   1. Re-run ETL pipeline: python src/data_pipeline/etl_pipeline.py")
    print("   2. It will re-download/generate data")
    print("   3. Your 19,997 processed reviews can be recreated")
    print("   4. All cleaning and processing logic is preserved")
    
    print(f"\nüí° PREVENTION:")
    print("   - Raw data files now properly excluded by .gitignore")
    print("   - Only processed results and code tracked in git")
    print("   - Database files excluded from version control")

def main():
    """Main check function"""
    print("üîç DATA RECOVERY STATUS CHECK")
    print("=" * 60)
    print(f"Time: {datetime.now()}")
    print("=" * 60)
    
    # Check file system
    db_files = check_file_system()
    
    # Check database content
    if db_files:
        check_database_content(db_files)
    
    # Check your processed data specifically
    data_intact = check_processed_data()
    
    # Check ETL reports
    check_etl_reports()
    
    # Provide recommendations
    recovery_recommendations()
    
    # Final status
    print(f"\n" + "=" * 60)
    if data_intact:
        print("üéâ GOOD NEWS: Your processed data appears to be intact!")
        print("   Your Day 1 work is preserved and ready for Day 2")
    else:
        print("‚ö†Ô∏è  Data needs to be regenerated")
        print("   But don't worry - your code is safe and can recreate everything")
    
    print("=" * 60)

if __name__ == "__main__":
    main()